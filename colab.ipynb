{"cells":[{"cell_type":"markdown","metadata":{"id":"Uss5I9O4cgmh"},"source":["This notebook can be used in Google colab to train, test, and evaluate different versions of BLIP 2 on the NYTimes cartoon image captioning dataset."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4079,"status":"ok","timestamp":1713307834987,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"WKNUni9OcoNB"},"outputs":[],"source":["import sys\n","import os\n","import torch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21089,"status":"ok","timestamp":1713307856070,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"ASEke_X7crSo","outputId":"7a077dc3-0717-4855-93b5-21cd6230f147"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"pLqX1xgikslG"},"source":["Clone the repo to your Google Drive and change `project_dir` to match your file structure."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1976,"status":"ok","timestamp":1713307858041,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"REBXeKxBkQdv","outputId":"e9f9291f-c098-4f5f-9a60-6d50486ee5ac"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Projects/Python_Projects/blip2cap'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["project_dir = '/content/drive/MyDrive/Projects/Python_Projects/blip2cap'\n","os.chdir(project_dir)\n","os.getcwd()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86588,"status":"ok","timestamp":1713307944623,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"qt5qVEvsci00","outputId":"ec9d9c68-0abc-408a-909a-cf6395591e16"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -r requirements.colab.txt -q;"]},{"cell_type":"markdown","metadata":{"id":"TRLup8A21QSY"},"source":["Use this cell to train or test with any model by passing arguments as follows.\n","TRAIN.ENABLE True\n","TRAIN.EPOCHS 5"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":150328,"status":"ok","timestamp":1713308094939,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"RaaSpFKeJ6p2","outputId":"f890f683-c30a-4ec9-a42e-6b615fd8a28d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your WandB API key: 4db8b749fdf8d2d397c6ab1fde5efb823aa1b908\n"]}],"source":["# running without a key will run but not push results to the website\n","os.environ[\"WANDB_API_KEY\"] = input(\"Please enter your WandB API key: \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkB7TEwzGsd6"},"outputs":[],"source":["4db8b749fdf8d2d397c6ab1fde5efb823aa1b908"]},{"cell_type":"markdown","metadata":{"id":"mgGLKp6unKom"},"source":["# Adding models\n","\n","1.   Duplicate this file into the same dir `models/baseline_models.py`\n","2.   Change the file name to represent your model contributions\n","3.   Build your model(s) as functions like `def opt_2_7(cfg)`\n","4.   In `model_builder.py`\n","import your model functions `from .baseline_models import opt_2_7`\n","register your model functions `MODEL_REGISTRY.register(opt_2_7)`\n","5.   Create a config file for each model like `configs/opt_2_7_base.yaml`\n","6.   ARCH key `opt_2_7` must match your model function name\n","(or instead of 5 and 6 use `MODEL.ARCH blip2_quant` in CLI\n","\n","# Run experiments\n","1.   Add your wandb key to log results in group project\n","2.   Run experiments using following cell\n","3.   Control hyperparameters with command line\n","4.   Make sure .yaml points to your config file\n","\n","# Example command line arguments\n","* --cfg \"configs/blip2_quant.yaml\" (points to model config file)\n","* TRAIN.ENABLE True (train + test after each epoch OR just test\n","* TRAIN.EPOCHS 1\n","* TRAIN.NUM_BATCHES -1 (-1 is all, smaller number for debugging)\n","* TEST.NUM_BATCHES -1 (-1 is all, smaller number for debugging)\n","* MODEL.NOTES \"No PEFT\" (run comments for wandb run)\n","\n","# Weights and Biases\n","Saves the final output of each caption to 'files'\n","Currently, no way to save models. LMK if that is necessary.\n","\n"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416927,"status":"ok","timestamp":1713313072720,"user":{"displayName":"Jason Sheinkopf","userId":"09415621891383882097"},"user_tz":-540},"id":"qQYGMUGXfSHe","outputId":"c71c8b5e-4aea-4b77-9fec-e839a527ca94"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-04-17 00:11:00.488788: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-17 00:11:00.488838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-17 00:11:00.490185: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-17 00:11:01.731155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","Running with config\n","DATA:\n","  ANNOTATION: explanation\n","  DATASET: mhessel/newyorker_caption_contest\n","  FEATURE: image_description\n","  PROCESSOR: Salesforce/blip2-opt-2.7b\n","MODEL:\n","  ARCH: opt_2_7\n","  BASE_MODEL: Salesforce/blip2-opt-2.7b\n","  CHECKPOINT_DIR: checkpoints\n","  CHECKPOINT_FILE_PATH: \n","  DEVICE: cuda\n","  DROPOUT_RATE: 0.15\n","  L2_REG: 0.15\n","  LORA_DROPOUT: 0.15\n","  NOTES: No PEFT\n","  OUTPUT_DIR: \n","RNG: 42\n","TEST:\n","  BATCH_SIZE: 4\n","  DATASET: nytimes\n","  NUM_BATCHES: 1\n","TRAIN:\n","  AUTO_RESUME: True\n","  BATCH_SIZE: 4\n","  CHECKPOINT_PERIOD: 1\n","  ENABLE: True\n","  EPOCHS: 1\n","  EVAL_PERIOD: 2\n","  NUM_BATCHES: 10\n","  WANDB_ENTITY: captioneers\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjasonsheinkopf\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjasonsheinkopf\u001b[0m (\u001b[33mcaptioneers\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/Projects/Python_Projects/blip2cap/wandb/run-20240417_001109-aln37v5l\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mopt_2_7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/captioneers/blip2cap\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/captioneers/blip2cap/runs/aln37v5l\u001b[0m\n","Loading checkpoint shards: 100% 2/2 [01:18<00:00, 39.48s/it]\n","trainable params: 5,296,128 || all params: 3,749,976,064 || trainable%: 0.1412309814679393\n","Training with config:\n","DATA:\n","  ANNOTATION: explanation\n","  DATASET: mhessel/newyorker_caption_contest\n","  FEATURE: image_description\n","  PROCESSOR: Salesforce/blip2-opt-2.7b\n","MODEL:\n","  ARCH: opt_2_7\n","  BASE_MODEL: Salesforce/blip2-opt-2.7b\n","  CHECKPOINT_DIR: checkpoints\n","  CHECKPOINT_FILE_PATH: \n","  DEVICE: cuda\n","  DROPOUT_RATE: 0.15\n","  L2_REG: 0.15\n","  LORA_DROPOUT: 0.15\n","  NOTES: No PEFT\n","  OUTPUT_DIR: \n","RNG: 42\n","TEST:\n","  BATCH_SIZE: 4\n","  DATASET: nytimes\n","  NUM_BATCHES: 1\n","TRAIN:\n","  AUTO_RESUME: True\n","  BATCH_SIZE: 4\n","  CHECKPOINT_PERIOD: 1\n","  ENABLE: True\n","  EPOCHS: 1\n","  EVAL_PERIOD: 2\n","  NUM_BATCHES: 10\n","  WANDB_ENTITY: captioneers\n","\n","==================================================\n","Training epoch: 0\n","==================================================\n","\n","/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n"," Batch 0 train loss: 6.078125\n"," Batch 1 train loss: 5.49609375\n"," Batch 2 train loss: 3.90625\n"," Batch 3 train loss: 5.8359375\n"," Batch 4 train loss: 5.55078125\n"," Batch 5 train loss: 4.5234375\n"," Batch 6 train loss: 4.47265625\n"," Batch 7 train loss: 3.943359375\n"," Batch 8 train loss: 4.0859375\n"," Batch 9 train loss: 3.896484375\n","\n","Epoch 0 training loss: 4.77890625\n","\n","==================================================\n","Testing.\n","==================================================\n","\n","\n","Test loss: 4.10546875\n","gen text list\n","input text list\n","{'bleu': 0.031318772513038926, 'rouge_1_f1': 0.28411695566261236, 'meteor': 0.17825719143716812}\n","Epoch: 0, Train Loss: 4.77890625, Test Loss: 4.10546875\n","gen text list\n","input text list\n","{'bleu': 0.031318772513038926, 'rouge_1_f1': 0.28411695566261236, 'meteor': 0.17825719143716812}\n","\n","Final captions\n","0: two people standing on a mountain with a bigfoot in the background\n","1: a man is standing in front of a casket\n","2: a drawing of a bird in a cage\n","3: a man is standing in front of a door and a dog is standing next to him\n","4: a cartoon of a man in a wheelchair being helped by two men\n","5: a man in a top hat is standing next to a man in a suit\n","6: two dogs are standing next to each other\n","7: a cartoon of a man standing in front of a train\n","8: two men with backpacks walking towards a train\n","9: a man sits at a desk in a large office building\n","10: a man and woman are standing under an umbrella\n","11: a man and woman are in a hotel room, and there is a suitcase on the bed. the man is talking to the woman, and there is a suitcase on the bed. the man is saying, \"\n","12: a man in a hospital bed is talking to a woman in a hospital bed\n","13: a cartoon drawing of a meeting room with people sitting around a table\n","14: two people are walking by a large sandwich\n","15: a drawing of birds flying over a city\n","16: a man is sitting at a table with a sign on it\n","17: a cartoon of a man and woman sitting at a table with a man playing a trumpet\n","18: a man is sitting at a table with a train engine sitting in the middle of the room\n","19: a man is giving a toast to a piece of bread\n","20: a man is sitting in a chair and a man is laying on the bed\n","21: an elevator with a woman in a suit and a man in a suit standing in the elevator\n","22: a man is standing on a ledge with a bird on his shoulder\n","23: a man and woman are sitting in a chair and the man is talking to the woman\n","24: a man and woman sit on the ground and look at each other\n","25: snow white drawing - snow white drawing by elizabeth walden\n","26: a man in a suit is sitting at a desk with a hooded man sitting next to him\n","27: a man is sitting on a cake with a woman sitting on the other side\n","28: two men are on skis and one is sitting on the ground\n","29: a cartoon of a cow and a bull\n","30: a cartoon dog and sheep are standing in a field\n","31: a cartoon of people hanging from a rope\n","32: a black and white drawing of a man with a parachute\n","33: two men are kneeling down and one is holding a bone\n","34: a man sits at a desk with a bull sitting on his lap\n","35: a man is running with a surfboard\n","36: a man and woman sit on a couch, and a child sits on a chair\n","37: two men are standing on a hill with a bike in front of them\n","38: a man is walking down the street and there are people walking by him\n","39: two chefs standing in a tunnel\n","40: a cartoon of a man in a hospital bed with a woman standing next to him\n","41: a cartoon drawing of a man in bed with a dog\n","42: a man is standing at a desk with a man standing next to him\n","43: a cartoon of a man standing in front of a display case with a turkey on it\n","44: a man is talking to another man\n","45: an illustration of a boat in the ocean with people on it\n","46: a man and a woman are standing next to a motorcycle\n","47: a woman sits in front of a car and a woman is sitting in front of a computer\n","48: two cartoon godzillas are fighting over a city\n","49: a woman sits on a couch and looks out a window\n","50: a man is standing in front of a house with a slide\n","51: a baby is in a crib and a woman is sitting in the bed\n","52: a cartoon of a man sitting on a chair and a wave coming towards him\n","53: two men sitting on a cloud with angels sitting on their shoulders\n","54: a cartoon of two people standing in front of a desk with a sign that says \"out of office\"\n","55: a cartoon drawing of two people sitting in front of a television\n","56: a man is standing in front of a pharmacy\n","57: a group of people sitting on a ledge\n","58: a man is sitting in a chair in front of a large screen\n","59: a man sitting on a couch with a cat looking out the window\n","60: a caveman is standing next to a woman and a child\n","61: two men are talking to each other\n","62: a woman is sitting at a table with a sign that says \"I'm sorry, I didn't see you.\"\n","63: a cartoon drawing of a man and a dog flying over a city\n","64: an oil rig with people on it\n","65: a cartoon man is standing in front of a city with smoke coming out of the buildings\n","66: a cartoon of a hippo sitting on a couch with two people sitting on the couch\n","67: a man and woman are standing in front of a coffin\n","68: a man and a dog are standing in front of a house\n","69: a cartoon of a meeting with people sitting at a table\n","70: a man is sitting at a table with a woman and a man sitting at the table\n","71: a man is sitting in a cage with a dog\n","72: a cartoon of a judge and two people sitting at a table\n","73: a cartoon of a man sitting at a desk with a lobster on his lap\n","74: a man in a suit is sitting at a desk with a bird on his shoulder\n","75: a cartoon drawing of a man holding a remote control\n","76: a man in a suit is talking to a man in a suit\n","77: a woman is talking to a man in a restaurant\n","78: a man is standing on a ladder and another man is standing on a ladder next to him\n","79: a man and woman are standing in front of a microwave\n","80: a man in a suit is sitting at a desk with papers on it\n","81: two firefighters standing next to a pole\n","82: a man and woman are sitting at a table with a man in a cowboy hat and a woman in a dress\n","83: a man is sitting at a desk and a woman is standing next to him\n","84: a cartoon of a lion and a man sitting on the ground\n","85: a man is sitting at a desk with a pile of papers and a computer\n","86: a cartoon of a woman climbing a rock wall\n","87: a man in a boat is holding a fishing rod\n","88: a cartoon of a man and woman standing on a tree branch, with a bird perched on the branch\n","89: a man stands on a pile of rocks and another man stands on a pile of rocks\n","90: a man is sitting in a chair and another man is standing next to him\n","91: a cartoon of two men on horses\n","92: a pigeon is perched on a ledge\n","93: two people sitting on a nest\n","94: a man in a wheelchair is talking to another man\n","95: a man sitting in a chair with a man sitting on a chair in front of him\n","96: two skeletons are standing in front of a building\n","97: a man is sitting in a hammock\n","98: a man is sweeping the sidewalk and a man is standing in the doorway\n","99: a man is standing in front of a large room with people sitting in chairs\n","100: a man and woman are standing in the woods, one holding a plate of food and the other holding a knife.\n","101: an image of a fish and a skeleton\n","102: a cartoon drawing of a man holding a sword and a dragon\n","103: a man and woman are standing in front of a casket\n","104: two people are standing next to a bear\n","105: two men are sitting at a table with a board game in the background\n","106: a man and woman walking down the street, one holding a lobster and the other holding a lobster claw\n","107: a woman is standing in front of an open door\n","108: a man sits on a couch with a baby in his lap\n","109: a man is sitting in a cave with a car parked in the background\n","110: a doctor is holding a syringe\n","111: a cartoon of people riding horses\n","112: a man and woman are in a room with broken glass and furniture\n","113: two pigs are in a box with a pig bank\n","114: a man in a suit is kneeling down and talking to a man in a suit\n","115: a cartoon of two men in boots and one man is holding a box with a shoe in it\n","116: a man sits at a desk with a computer screen and a phone\n","117: a man sits on a couch and a giraffe is sitting on the floor\n","118: a man is sitting in a chair and a woman is sitting in a chair\n","119: a man and woman are sitting on an inflatable raft in the ocean\n","120: a man in a hospital bed is sitting at a desk and a woman is sitting in a chair next to the bed\n","121: a woman is pouring coffee into a cup\n","122: a mouse is talking to a woman in a lab\n","123: a man is standing in front of a sign that says \"math\" and a man is sitting in a car next to the sign\n","124: an angel is sitting on a box and another angel is sitting on a chair\n","125: a man is standing in front of a house with a car in the driveway\n","126: a man is sitting in a bed and talking to another man\n","127: a man in a suit is sitting in a hammock\n","128: a cartoon of a man and woman sitting on a bed\n","129: a man is talking to another man\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:       bleu â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:     meteor â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: rouge_1_f1 â–\n","\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss â–ˆâ–†â–â–‡â–†â–ƒâ–ƒâ–â–‚â–\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:       bleu 0.03132\n","\u001b[34m\u001b[1mwandb\u001b[0m:     meteor 0.17826\n","\u001b[34m\u001b[1mwandb\u001b[0m: rouge_1_f1 0.28412\n","\u001b[34m\u001b[1mwandb\u001b[0m:  test_loss 4.10547\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 3.89648\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run \u001b[33mopt_2_7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/captioneers/blip2cap/runs/aln37v5l\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/captioneers/blip2cap\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240417_001109-aln37v5l/logs\u001b[0m\n"]}],"source":["!python tools/run_net.py --cfg \"configs/opt_2_7_base.yaml\" TRAIN.ENABLE True TRAIN.EPOCHS 1 TRAIN.NUM_BATCHES 10 TEST.NUM_BATCHES -1 TEST.NUM_BATCHES 1 MODEL.NOTES \"No PEFT\";"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
